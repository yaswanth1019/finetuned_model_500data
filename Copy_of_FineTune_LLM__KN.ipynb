{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMct87SVUnO5",
        "outputId": "f7eee3da-9a2d-413b-e3c0-40b7cec26a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf2 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: bitsandbytes in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (0.47.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (2.7.1+cu128)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from bitsandbytes) (2.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pypdf2 bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGR0N4B1UfOG",
        "outputId": "c4160c5c-9be2-47d6-aa0c-855f7b2a9d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted 135 Q/A pairs into tirumala_dataset.jsonl\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Load PDF\n",
        "pdf_path = \"New_QuestionBank.pdf\"\n",
        "reader = PdfReader(pdf_path)\n",
        "\n",
        "# Extract text from PDF\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text() + \"\\n\"\n",
        "\n",
        "# Regex to capture Q/A pairs\n",
        "qa_pairs = re.findall(r\"Q:\\s*(.*?)\\s*A:\\s*(.*?)(?=Q:|$)\", text, re.DOTALL)\n",
        "\n",
        "dataset = []\n",
        "for q, a in qa_pairs:\n",
        "    q = q.strip().replace(\"\\n\", \" \")\n",
        "    a = a.strip().replace(\"\\n\", \" \")\n",
        "\n",
        "    # Format according to your FormatDataset style\n",
        "    record = {\n",
        "        \"instruction\": q,\n",
        "        \"output\": a\n",
        "    }\n",
        "    dataset.append(record)\n",
        "\n",
        "# Save as JSONL\n",
        "out_path = Path(\"tirumala_dataset.jsonl\")\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for item in dataset:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Converted {len(dataset)} Q/A pairs into {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MD5a8Kb0OKPf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9cb38b7e90ca403789373d640cd70113",
            "cab68dcd70ee4d2698718b59c22cccfe",
            "3eee4e5230c34bbdbc7f97ee33e19c5a",
            "a8f0b396e21e40b289318f695268308b",
            "9e72e76a45094a509890def729a75349",
            "ff644b2cf1534426a1e492736334268e",
            "b8764d761267429a9e01bdc043253aae",
            "6e059801e3334364b37da33a156f5ff9",
            "69e080fa647b4c49bc250e99fe387592",
            "866f5f66842948d48d3061fa0eee552e",
            "9463b7e2bccf42638e7620baa635c835"
          ]
        },
        "id": "7uTUhvBlOKMv",
        "outputId": "8dbdd6e6-08e9-4460-ff15-b66ab1d80c28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 135 examples [00:00, 14944.86 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 1. Load Dataset\n",
        "# ==============================\n",
        "dataset = load_dataset(\"json\", data_files=\"tirumala_dataset.jsonl\")\n",
        "\n",
        "# Split into train/validation\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMQ4DNerfnLe",
        "outputId": "d038d97f-1752-4afd-e948-737af14bf83d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'output'],\n",
              "    num_rows: 14\n",
              "})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5ESZ3yxfYVk",
        "outputId": "b0159e64-f9c5-40ea-9ede-940aac36bff6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Column(['How   can   I   get   a   Laddu   prasadam?', 'How   many   steps   are   there   in   Alipiri   Mettu   and   Srivari   Mettu?', 'Where   can   I   get   laddu   prasadam   after   darshan?', 'What   are   the   options   for   public   transport   from   Tirupati   to   Tirumala?', 'What   sevas   and   rituals   can   devotees   participate   in?'])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['test']['instruction']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acgMsQHLfiRe",
        "outputId": "a2b49a62-38a1-4adf-a4cb-a02fdca445e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Column(['After   darshan,   you   can   purchase   the   famous   Tirupati   Laddu   at   the   designated   counters.   Each   darshan   token   often   includes   a   free   Laddu   as   well.', 'Alipiri   Mettu   has   about   3,550   steps   covering   a   distance   of   9   km,   taking   3–4   hours   to   climb.   Srivari   Mettu   has   about   2,388   steps   with   a   shorter   distance   of   2.1   km,   taking   around   2–3   hours   to   climb.', 'After   darshan,   every   pilgrim   receives   laddu   prasadam   at   the   Laddu   Counter   inside   the   temple   complex .   Additional   laddus   can   be   purchased.', 'APSRTC   runs   frequent   bus   services   from   various   points   in   Tirupati,   including   the   railway   station   and   bus   stand,   to   Tirumala.', 'Important   sevas   include:   Daily   Sevas :   Suprabhatam,   Thomala   Seva,   Archana,   Ekantha   Seva,   Weekly   Sevas :   Kalyanotsavam,   Sahasra   Deepalankarana,   Annual   Events :   Brahmotsavam,   Vaikunta   Ekadasi.     Most   seva   tickets   require   advance   booking.'])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['test']['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "38CVmnRcPnhW"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:28<00:00,  7.06s/it]\n"
          ]
        }
      ],
      "source": [
        "##optional\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,  # or load_in_4bit=True\n",
        "    llm_int8_enable_fp32_cpu_offload=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"   # lets HF place layers across GPU/CPU\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szEloUT7OKJX",
        "outputId": "c5b0a398-30b9-4754-af51-ff91660e40ef"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 2. Model & Tokenizer\n",
        "# ==============================\n",
        "# MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"   # <-- Changed to a public model\n",
        "\n",
        "\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
        "# tokenizer.pad_token = tokenizer.eos_token  # ensure pad token is defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "11266fda8db9408c86801344a3c29629",
            "5cba32fb5dd544a5a0186f97004174dc",
            "1fea8aaefffc4a4693d3e6488750c2db",
            "852fb52f4d8f44938b7a26ca01da2c01",
            "d69cb84fc36d4ada9992cd6e4c11c792",
            "486af92638c2440288933fb195dbeed9",
            "1a2edb7911594e19a430d10fd95be3c6",
            "55bdf303b43447f0b08d1bddff3f7ef8",
            "2cd4b1de7a3541d681b2b364bfcbae54",
            "3d4c45c6f290444e9175ab3e4db1c2dd",
            "207627beb01e4d409aa1a3ed3ee137f2",
            "e150bccfa84f469ebd2d27b44cae258e",
            "85d03a29f43745aaae28350410618c4a",
            "e5925fbc0e5d4bed9737686d3d9b57f6",
            "bce12071c2e9489e88265b0ec1a637ad",
            "fc9845e11eed45ca95f66cb79066c459",
            "049e3318c88142ac810b4d9895ca7b0f",
            "2291eb1b2a9a4b4ea9dbacfe23fb3fc6",
            "6c775065d37f4c8c8de7d1ccf7cc68ea",
            "85b792e0fd354ebc83da59eb280c94c6",
            "8fca053d0ec34e4d8dcc738044860136",
            "957ac40ce61a4bdfa090978de81d8f10"
          ]
        },
        "id": "LS_6mbxaOKGn",
        "outputId": "b89af9ef-dfad-45c1-a4cb-3145036b8d65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 121/121 [00:00<00:00, 1235.22 examples/s]\n",
            "Map: 100%|██████████| 14/14 [00:00<00:00, 736.89 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 3. Tokenize Function\n",
        "# ==============================\n",
        "def tokenize_function(example):\n",
        "    tokenized_example = tokenizer(\n",
        "        str(example[\"instruction\"]) + \" \" + str(example[\"output\"]), # Ensure values are strings before concatenation\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        padding=\"max_length\" # Add padding to ensure uniform length\n",
        "    )\n",
        "    return {\n",
        "        \"input_ids\": tokenized_example[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized_example[\"attention_mask\"],\n",
        "        \"labels\": tokenized_example[\"input_ids\"].copy(),\n",
        "        \"instruction\": example[\"instruction\"], # Keep original instruction\n",
        "        \"output\": example[\"output\"] # Keep original output\n",
        "    }\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=False) # Process without batching\n",
        "\n",
        "# Set dataset format to torch to help data collator\n",
        "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels', 'instruction', 'output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub[hf_xet] in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (0.34.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (4.12.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from huggingface_hub[hf_xet]) (1.1.10)\n",
            "Requirement already satisfied: colorama in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[hf_xet]) (0.4.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (from requests->huggingface_hub[hf_xet]) (2025.8.3)\n",
            "Requirement already satisfied: hf_xet in c:\\users\\dr himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages (1.1.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub[hf_xet] \n",
        "!pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "63fd67fbdaad4b18a359813e95b9832f",
            "170883c117d44ababf4157b7dbbe70a5",
            "3bb7bc4b77d8463cb94be6fffe22a8f8",
            "69e5017d02a54b2f89dba1d7252298bf",
            "aebf7b68b62b4540935a63c9ea4968a8",
            "6b8d4f04d25a47eba337b1d33e140145",
            "b994ad873761444aa85c6daddf14927e",
            "cd8b8ac89e3d4b609dba494713bac109",
            "53943844aa0f4ff29bf687c3154bcb34",
            "9e06def42df34245be46e03c5547faed",
            "21adc4e4a587499580d9e3ccc96c083c"
          ]
        },
        "id": "K3TD8TeJOKC4",
        "outputId": "9702a030-bf75-4223-f192-6fe00f1449e8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 16\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 1. Define the quantization configuration\u001b[39;00m\n\u001b[0;32m      9\u001b[0m quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m     10\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[0;32m     13\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# LoRA config\u001b[39;00m\n\u001b[0;32m     23\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[0;32m     24\u001b[0m     r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     25\u001b[0m     lora_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAUSAL_LM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Dr Himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    605\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    610\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Dr Himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\modeling_utils.py:288\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
            "File \u001b[1;32mc:\\Users\\Dr Himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\modeling_utils.py:5157\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   5155\u001b[0m \u001b[38;5;66;03m# Prepare the full device map\u001b[39;00m\n\u001b[0;32m   5156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5157\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m \u001b[43m_get_device_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5159\u001b[0m \u001b[38;5;66;03m# Finalize model weight initialization\u001b[39;00m\n\u001b[0;32m   5160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_tf:\n",
            "File \u001b[1;32mc:\\Users\\Dr Himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\modeling_utils.py:1473\u001b[0m, in \u001b[0;36m_get_device_map\u001b[1;34m(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)\u001b[0m\n\u001b[0;32m   1470\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m infer_auto_device_map(model, dtype\u001b[38;5;241m=\u001b[39mtarget_dtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdevice_map_kwargs)\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m         \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1476\u001b[0m     tied_params \u001b[38;5;241m=\u001b[39m find_tied_parameters(model)\n",
            "File \u001b[1;32mc:\\Users\\Dr Himangshu\\.conda\\envs\\pytorch_gpu\\lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:117\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`from_pretrained`. Check \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. "
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 4. Load Base Model + LoRA\n",
        "# ==============================\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# 1. Define the quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v-7KTS_OKAn"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 5. Training Arguments\n",
        "# ==============================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned_model\",\n",
        "    eval_strategy=\"epoch\", # Replaced evaluation_strategy with eval_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=25,\n",
        "    save_total_limit=2,\n",
        "    push_to_hub=False,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=100,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q3OWhXbOJ12"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 6. Trainer\n",
        "# ==============================\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    processing_class=tokenizer, # Use processing_class instead of tokenizer\n",
        "    data_collator=data_collator, # Add data collator for padding\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "qWvO-9nLOJxk",
        "outputId": "ed21b57b-dad0-4355-f864-5e4500cd8958"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [160/160 36:51, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.420450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.332589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.171201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.272900</td>\n",
              "      <td>1.946551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.272900</td>\n",
              "      <td>1.713401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.272900</td>\n",
              "      <td>1.478219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.726300</td>\n",
              "      <td>1.329298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.726300</td>\n",
              "      <td>1.197964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.726300</td>\n",
              "      <td>1.140367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.068500</td>\n",
              "      <td>1.092266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.068500</td>\n",
              "      <td>1.039749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.068500</td>\n",
              "      <td>1.046221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.673200</td>\n",
              "      <td>1.024730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.673200</td>\n",
              "      <td>1.059803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.673200</td>\n",
              "      <td>1.092466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.376800</td>\n",
              "      <td>1.186721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.376800</td>\n",
              "      <td>1.330418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.376800</td>\n",
              "      <td>1.273203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.202300</td>\n",
              "      <td>1.350043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.202300</td>\n",
              "      <td>1.369835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=160, training_loss=0.996976638585329, metrics={'train_runtime': 2216.2264, 'train_samples_per_second': 1.092, 'train_steps_per_second': 0.072, 'total_flos': 1.551560953823232e+16, 'train_loss': 0.996976638585329, 'epoch': 20.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==============================\n",
        "# 7. Train Model\n",
        "# ==============================\n",
        "trainer.train()\n",
        "# d674e8f3b33ef23520bf99b3a5a7504c03fdaa2a - wandb api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rNbcorPcOJKO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fine-tuning complete! Model saved at ./finetuned_model\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 8. Save Model\n",
        "# ==============================\n",
        "model.save_pretrained(\"./finetuned_model\")\n",
        "tokenizer.save_pretrained(\"./finetuned_model\")\n",
        "\n",
        "print(\"✅ Fine-tuning complete! Model saved at ./finetuned_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kEzfUcwgCXS"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Loading and testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrgsgpW6gMCo"
      },
      "source": [
        "# Evaluating the model with test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TgnVpJl0i3hA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model and tokenizer loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Define the path where you saved the model and tokenizer\n",
        "saved_model_path = \"./finetuned_model\"\n",
        "\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
        "loaded_model = AutoModelForCausalLM.from_pretrained(saved_model_path)\n",
        "\n",
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "loaded_model.eval()\n",
        "if torch.cuda.is_available():\n",
        "    loaded_model.to(\"cuda\")\n",
        "\n",
        "print(\"✅ Model and tokenizer loaded successfully!\")\n",
        "\n",
        "# Example of how to use the loaded model for inference\n",
        "def generate_response(prompt, model, tokenizer, max_length=1024):\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Move input_ids to the same device as the model\n",
        "    if torch.cuda.is_available():\n",
        "        input_ids = input_ids.to(\"cuda\")\n",
        "\n",
        "    # Generate a response\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.eos_token_id # Use eos_token_id for padding\n",
        "        )\n",
        "\n",
        "    # Decode the generated output\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1mPf_6ldi9xO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt:\n",
            "Are there buses from Alipiri to Tirumala for those who get tired?\n",
            "\n",
            "Generated Response:\n",
            "Are there buses from Alipiri to Tirumala for those who get tired? Yes. There are buses from Alipiri to Tirumala that run regularly. However, the journey can be long and arduous, and it's advisable to take breaks and rest along the way. Many people opt for the TTD buses, which are cheaper and faster. It's also possible to hire a taxi or a rickshaw.  \n",
            "\n",
            "Buses from Alipiri usually depart every 30 minutes or so, depending on traffic. The journey takes around 2-3 hours, depending on the route. The TTD buses are also frequent and run continuously. The journey is usually shorter, but it can be more crowded.  \n",
            "\n",
            "It's always a good idea to arrive at the bus stand early, especially during peak hours, to avoid waiting in long queues. You can also book your ticket online in advance.  \n",
            "\n",
            "Remember to carry your ID, cash, and a small bag for your belongings. Also, dress appropriately, as the buses are often crowded and hot.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Are there buses from Alipiri to Tirumala for those who get tired?\"\n",
        "\n",
        "# Generate a response using the fine-tuned model\n",
        "response = generate_response(prompt, loaded_model, loaded_tokenizer)\n",
        "\n",
        "print(\"Prompt:\")\n",
        "print(prompt)\n",
        "print(\"\\nGenerated Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xIuAdzJgjGRu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt:\n",
            "Is drinking water available on the steps route?\n",
            "\n",
            "Generated Response:\n",
            "Is drinking water available on the steps route? Yes, there are water points along the steps route. However, it is advisable to bring your own water bottle. You can also buy bottled water at the starting point.  \n",
            "\n",
            "Is it safe to walk on the steps route at night? Yes, it is safe to walk on the steps route at night. The steps are lit up with LED lights, and there are security cameras to deter any potential theft. However, it is recommended to walk with a group or carry a flashlight.  \n",
            "\n",
            "Is it possible to walk the steps route in a wheelchair or with a stroller? Yes, the steps are designed to accommodate wheelchairs and strollers. However, it may be more challenging to climb the steps due to their steepness. It is recommended to hire a stroller or use a ramp to make the climb easier.  \n",
            "\n",
            "Is it possible to walk the steps route with a dog? Yes, dogs are allowed on the steps route. However, they should be kept on a leash and controlled at all times.  \n",
            "\n",
            "Is it possible to walk the steps route with a baby or small child? Yes, it is possible to walk the steps route with a baby or small child. However, they should be kept on a leash and supervised at all times.  \n",
            "\n",
            "Is it possible to walk the steps route with a group of friends or family? Yes, it is possible to walk the steps route with a group of friends or family. However, it may be more challenging to climb the steps due to their steepness. It is recommended to hire a stroller or use a ramp to make the climb easier.  \n",
            "\n",
            "Is it possible to walk the steps route with a group of strangers? Yes, it is possible to walk the steps route with a group of strangers. However, it may be more challenging to climb the steps due to their steepness. It is recommended to hire a stroller or use a ramp to make the climb easier.  \n",
            "\n",
            "Is it possible to walk the steps route with a group of friends or family on a weekend or holiday? Yes, it is possible to walk the steps route on weekends or holidays. However, it may be more crowded and busy due to the high footfall. It is recommended to hire a stroller or use a ramp to make the climb easier.  \n",
            "\n",
            "Is it possible to walk the steps route with a group of strangers on a weekend or holiday? Yes, it is possible to walk the steps route on weekends or holidays. However, it may be more crowded and busy due to the high footfall. It is recommended to hire a stroller or use a ramp to make the climb easier.  \n",
            "\n",
            "Is it possible to walk the steps route with a group of strangers on a weekday? Yes, it is possible to walk the steps route on weekdays. However, it may be less crowded and busy due to the weekday traffic. It is recommended to hire a stroller or use a ramp to make the climb easier.  \n",
            "\n",
            "Is it possible to walk the steps route at night? Yes, it is possible to walk the steps route at night. However, it is recommended to walk with a group or carry a flashlight.  \n",
            "\n",
            "Is it possible to walk the steps route in the rain? Yes, it is possible to walk the steps route in the rain. However, it may be more challenging to climb the steps due to their steepness. It is recommended to walk with a group or carry a raincoat.  \n",
            "\n",
            "Is it possible to walk the steps route in the winter? Yes, it is possible to walk the steps route in the winter. However, it may be more challenging to climb the steps due to the snow and ice. It is recommended to walk with a group or carry a warm jacket.  \n",
            "\n",
            "Is it possible to walk the steps route in the summer? Yes, it is possible to walk the steps route in the summer. However, it may be more challenging to climb the steps due to the heat and humidity. It is recommended to walk with a group or carry a lightweight shirt.  \n",
            "\n",
            "Is it possible to walk the steps route in the monsoon season? Yes, it is possible to walk the steps route in the monsoon season. However, it may be more challenging to climb the steps due to the rain and mud. It is recommended to walk with a group or carry a raincoat.  \n",
            "\n",
            "Is it possible to walk the steps route in the winter season? Yes, it is possible to walk the steps route in the winter season. However, it may be more\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Is drinking water available on the steps route?\"\n",
        "\n",
        "# Generate a response using the fine-tuned model\n",
        "response = generate_response(prompt, loaded_model, loaded_tokenizer)\n",
        "\n",
        "print(\"Prompt:\")\n",
        "print(prompt)\n",
        "print(\"\\nGenerated Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch_gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "049e3318c88142ac810b4d9895ca7b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11266fda8db9408c86801344a3c29629": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cba32fb5dd544a5a0186f97004174dc",
              "IPY_MODEL_1fea8aaefffc4a4693d3e6488750c2db",
              "IPY_MODEL_852fb52f4d8f44938b7a26ca01da2c01"
            ],
            "layout": "IPY_MODEL_d69cb84fc36d4ada9992cd6e4c11c792"
          }
        },
        "170883c117d44ababf4157b7dbbe70a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b8d4f04d25a47eba337b1d33e140145",
            "placeholder": "​",
            "style": "IPY_MODEL_b994ad873761444aa85c6daddf14927e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1a2edb7911594e19a430d10fd95be3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fea8aaefffc4a4693d3e6488750c2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55bdf303b43447f0b08d1bddff3f7ef8",
            "max": 145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cd4b1de7a3541d681b2b364bfcbae54",
            "value": 145
          }
        },
        "207627beb01e4d409aa1a3ed3ee137f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21adc4e4a587499580d9e3ccc96c083c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2291eb1b2a9a4b4ea9dbacfe23fb3fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cd4b1de7a3541d681b2b364bfcbae54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bb7bc4b77d8463cb94be6fffe22a8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd8b8ac89e3d4b609dba494713bac109",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53943844aa0f4ff29bf687c3154bcb34",
            "value": 4
          }
        },
        "3d4c45c6f290444e9175ab3e4db1c2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eee4e5230c34bbdbc7f97ee33e19c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e059801e3334364b37da33a156f5ff9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69e080fa647b4c49bc250e99fe387592",
            "value": 1
          }
        },
        "486af92638c2440288933fb195dbeed9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53943844aa0f4ff29bf687c3154bcb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55bdf303b43447f0b08d1bddff3f7ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cba32fb5dd544a5a0186f97004174dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486af92638c2440288933fb195dbeed9",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2edb7911594e19a430d10fd95be3c6",
            "value": "Map: 100%"
          }
        },
        "63fd67fbdaad4b18a359813e95b9832f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_170883c117d44ababf4157b7dbbe70a5",
              "IPY_MODEL_3bb7bc4b77d8463cb94be6fffe22a8f8",
              "IPY_MODEL_69e5017d02a54b2f89dba1d7252298bf"
            ],
            "layout": "IPY_MODEL_aebf7b68b62b4540935a63c9ea4968a8"
          }
        },
        "69e080fa647b4c49bc250e99fe387592": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69e5017d02a54b2f89dba1d7252298bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e06def42df34245be46e03c5547faed",
            "placeholder": "​",
            "style": "IPY_MODEL_21adc4e4a587499580d9e3ccc96c083c",
            "value": " 4/4 [01:19&lt;00:00, 18.45s/it]"
          }
        },
        "6b8d4f04d25a47eba337b1d33e140145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c775065d37f4c8c8de7d1ccf7cc68ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e059801e3334364b37da33a156f5ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "852fb52f4d8f44938b7a26ca01da2c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d4c45c6f290444e9175ab3e4db1c2dd",
            "placeholder": "​",
            "style": "IPY_MODEL_207627beb01e4d409aa1a3ed3ee137f2",
            "value": " 145/145 [00:00&lt;00:00, 501.18 examples/s]"
          }
        },
        "85b792e0fd354ebc83da59eb280c94c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85d03a29f43745aaae28350410618c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_049e3318c88142ac810b4d9895ca7b0f",
            "placeholder": "​",
            "style": "IPY_MODEL_2291eb1b2a9a4b4ea9dbacfe23fb3fc6",
            "value": "Map: 100%"
          }
        },
        "866f5f66842948d48d3061fa0eee552e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fca053d0ec34e4d8dcc738044860136": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9463b7e2bccf42638e7620baa635c835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "957ac40ce61a4bdfa090978de81d8f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cb38b7e90ca403789373d640cd70113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cab68dcd70ee4d2698718b59c22cccfe",
              "IPY_MODEL_3eee4e5230c34bbdbc7f97ee33e19c5a",
              "IPY_MODEL_a8f0b396e21e40b289318f695268308b"
            ],
            "layout": "IPY_MODEL_9e72e76a45094a509890def729a75349"
          }
        },
        "9e06def42df34245be46e03c5547faed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e72e76a45094a509890def729a75349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f0b396e21e40b289318f695268308b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866f5f66842948d48d3061fa0eee552e",
            "placeholder": "​",
            "style": "IPY_MODEL_9463b7e2bccf42638e7620baa635c835",
            "value": " 162/0 [00:00&lt;00:00, 8452.16 examples/s]"
          }
        },
        "aebf7b68b62b4540935a63c9ea4968a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8764d761267429a9e01bdc043253aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b994ad873761444aa85c6daddf14927e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce12071c2e9489e88265b0ec1a637ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fca053d0ec34e4d8dcc738044860136",
            "placeholder": "​",
            "style": "IPY_MODEL_957ac40ce61a4bdfa090978de81d8f10",
            "value": " 17/17 [00:00&lt;00:00, 207.38 examples/s]"
          }
        },
        "cab68dcd70ee4d2698718b59c22cccfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff644b2cf1534426a1e492736334268e",
            "placeholder": "​",
            "style": "IPY_MODEL_b8764d761267429a9e01bdc043253aae",
            "value": "Generating train split: "
          }
        },
        "cd8b8ac89e3d4b609dba494713bac109": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69cb84fc36d4ada9992cd6e4c11c792": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e150bccfa84f469ebd2d27b44cae258e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85d03a29f43745aaae28350410618c4a",
              "IPY_MODEL_e5925fbc0e5d4bed9737686d3d9b57f6",
              "IPY_MODEL_bce12071c2e9489e88265b0ec1a637ad"
            ],
            "layout": "IPY_MODEL_fc9845e11eed45ca95f66cb79066c459"
          }
        },
        "e5925fbc0e5d4bed9737686d3d9b57f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c775065d37f4c8c8de7d1ccf7cc68ea",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85b792e0fd354ebc83da59eb280c94c6",
            "value": 17
          }
        },
        "fc9845e11eed45ca95f66cb79066c459": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff644b2cf1534426a1e492736334268e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
